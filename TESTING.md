# Backend Testing Guide

This guide covers local testing of the ML microservice and API gateway before deploying to the cloud.

## Phase 1.3: Local Backend Testing

### Prerequisites

1. **Install Docker Desktop**
   - Download from: https://www.docker.com/products/docker-desktop
   - Start Docker Desktop and wait for it to initialize
   - Verify: `docker --version`

2. **Model Files**
   - Ensure `data/clean/best_model.pkl` exists (506 KB)
   - Contains: LightGBM model + county encoder + feature names

3. **macOS Port 5000 Issue**
   - Port 5000 is used by AirPlay Receiver on macOS
   - docker-compose configured to use port 5001 externally
   - Or disable in: System Settings â†’ General â†’ AirDrop & Handoff

---

## Test 1: Python ML Service (Standalone)

### Start the Service Locally

```bash
# Navigate to ml_service directory
cd ml_service

# Start Flask server on port 5001 (avoid macOS AirPlay)
PORT=5001 python server.py
```

### Test Endpoints

```bash
# Health check
curl http://localhost:5001/health | python3 -m json.tool

# Expected output:
{
    "status": "ok",
    "service": "ML Prediction Service",
    "housing_model_loaded": true,
    "housing_model_type": "LGBMRegressor"
}

# Housing price prediction
curl -X POST http://localhost:5001/predict-housing \
  -H "Content-Type: application/json" \
  -d '{"property_type":"T","is_new":"N","duration":"F","county":"GREATER LONDON","year":2016,"month":6}'

# Expected output:
{
    "price": 511741.71,
    "confidence_lower": 267035.71,
    "confidence_upper": 756447.71,
    "model": "LightGBM",
    "features_used": 11
}

# Test different property type (Detached, new build, Manchester)
curl -X POST http://localhost:5001/predict-housing \
  -H "Content-Type: application/json" \
  -d '{"property_type":"D","is_new":"Y","duration":"F","county":"GREATER MANCHESTER","year":2017,"month":3}'

# Expected: Different price (~Â£275k)
```

---

## Test 2: Docker Compose (Full Stack)

### Start All Services

```bash
# From project root
cd /Users/marinjanushaj/Documents/Cloud-AI

# Build and start all containers
docker-compose up --build

# Or run in background
docker-compose up -d
```

### Service Ports

| Service | Internal | External | URL |
|---------|----------|----------|-----|
| ml-service | 5000 | 5001 | http://localhost:5001 |
| api-gateway | 8080 | 8080 | http://localhost:8080 |
| housing-app | 8501 | 8501 | http://localhost:8501 |

### Test Docker Services

```bash
# 1. Check all containers are running
docker-compose ps

# Expected:
# ml-service       running   5001/tcp
# api-gateway      running   8080/tcp
# housing-app      running   8501/tcp

# 2. Test ML Service health (direct)
curl http://localhost:5001/health | python3 -m json.tool

# 3. Test API Gateway health
curl http://localhost:8080/api/v1/health | python3 -m json.tool

# 4. Test housing prediction via API Gateway
curl -X POST http://localhost:8080/api/v1/predict/housing \
  -H "Content-Type: application/json" \
  -d '{"property_type":"T","is_new":"N","duration":"F","county":"GREATER LONDON","year":2016,"month":6}'

# 5. Access Streamlit app
open http://localhost:8501
```

### Monitor Logs

```bash
# View all logs
docker-compose logs -f

# View specific service
docker-compose logs -f ml-service
docker-compose logs -f api-gateway
docker-compose logs -f housing-app
```

### Stop Services

```bash
# Stop all containers
docker-compose down

# Stop and remove volumes
docker-compose down -v
```

---

## Test 3: API Gateway (Go Service)

### Build Go API Locally (Optional)

```bash
cd api

# Install dependencies
go mod download

# Run locally
go run main.go

# Or build binary
go build -o api-gateway main.go
./api-gateway
```

### Test API Gateway Endpoints

```bash
# Health check
curl http://localhost:8080/api/v1/health

# Housing prediction (validates input, forwards to ML service)
curl -X POST http://localhost:8080/api/v1/predict/housing \
  -H "Content-Type: application/json" \
  -d '{
    "property_type": "T",
    "is_new": "N",
    "duration": "F",
    "county": "GREATER LONDON",
    "year": 2016,
    "month": 6
  }'

# Test input validation (should return 400 error)
curl -X POST http://localhost:8080/api/v1/predict/housing \
  -H "Content-Type: application/json" \
  -d '{"property_type":"INVALID","year":1800}'
```

---

## Test Results Summary

### âœ… Successful Tests (Completed)

1. **Python ML Service**
   - âœ… Model bundle loads correctly (model + encoder + features)
   - âœ… Health check returns correct status
   - âœ… Predictions working for different property types
   - âœ… Prices vary correctly based on inputs
   - âœ… Confidence intervals calculated
   - âœ… Port 5001 configured to avoid macOS conflicts

2. **Example Test Cases**
   | Property Type | Location | New Build | Predicted Price | Status |
   |---------------|----------|-----------|-----------------|--------|
   | Terraced | Greater London | No | Â£511,742 | âœ… |
   | Detached | Greater Manchester | Yes | Â£274,782 | âœ… |

---

## Common Issues & Solutions

### Issue 1: Port 5000 Already in Use

**Symptom:**
```
Address already in use - Port 5000 is in use by another program
```

**Solutions:**
1. Use port 5001: `PORT=5001 python server.py`
2. Disable AirPlay Receiver (macOS):
   - System Settings â†’ General â†’ AirDrop & Handoff
   - Turn off "AirPlay Receiver"
3. docker-compose already configured to use 5001 externally

### Issue 2: Model File Not Found

**Symptom:**
```
WARNING:predict:Housing model not found at ../data/clean/best_model.pkl
```

**Solution:**
1. Run notebook 4 (`dataset1_uk_housing/4_model.ipynb`)
2. Ensure model is saved to `data/clean/best_model.pkl`
3. Verify file exists: `ls -lh data/clean/best_model.pkl`

### Issue 3: Docker Not Running

**Symptom:**
```
Cannot connect to the Docker daemon
```

**Solution:**
1. Start Docker Desktop application
2. Wait for Docker to fully initialize
3. Verify: `docker info`

### Issue 4: Dockerfile Build Fails

**Symptom:**
```
Error building ml-service
```

**Solution:**
1. Check `requirements.txt` in ml_service/
2. Ensure all dependencies are listed
3. Clean build: `docker-compose build --no-cache ml-service`

---

## Next Steps

After successful local testing:

1. **âœ… COMPLETED**
   - Phase 1.1: Python ML microservice
   - Phase 1.2: Go API gateway
   - Phase 3: Docker setup
   - Phase 1.3: Local backend testing (this guide)

2. **ðŸ”œ UP NEXT**
   - Phase 2.1: Deploy Streamlit apps to Streamlit Cloud
   - Phase 4: Create CI/CD pipelines (GitHub Actions)
   - Phase 5: Setup Oracle Cloud and deploy services
   - Phase 6: Add monitoring and documentation

---

## Testing Checklist

Before moving to deployment:

- [ ] Docker Desktop installed and running
- [ ] All containers start successfully
- [ ] ML service health check passes
- [ ] API gateway health check passes
- [ ] Housing predictions return valid prices
- [ ] Streamlit app accessible at localhost:8501
- [ ] Logs show no errors
- [ ] Can stop and restart services cleanly

---

## API Documentation Reference

### ML Service Endpoints

**Base URL:** `http://localhost:5001`

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Service health status |
| POST | `/predict-housing` | UK housing price prediction |
| POST | `/predict-electricity` | UK electricity demand (pending) |
| GET | `/models` | List available models |

### API Gateway Endpoints

**Base URL:** `http://localhost:8080/api/v1`

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Gateway health status |
| POST | `/predict/housing` | Housing prediction (with validation) |
| POST | `/predict/electricity` | Electricity prediction (pending) |

---

## Performance Metrics

From local testing:

- **Model Load Time:** ~2 seconds
- **Prediction Latency:** ~50ms (single request)
- **Container Startup:** ~10-15 seconds
- **Memory Usage:**
  - ml-service: ~150 MB
  - api-gateway: ~10 MB (Go efficiency!)
  - housing-app: ~200 MB

---

## Contact

For issues or questions:
- Project Lead: Marin Janushaj
- Deployment Lead: Alexandros Gkiorgkinis
