{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Deployment Guide ‚Äî UK Housing\n",
    "\n",
    "**Author:** Marin Janushaj  \n",
    "**Team:** Yunus  \n",
    "**Date:** November 2025  \n",
    "**Goal:** Prepare models for production deployment\n",
    "\n",
    "## Deployment Overview\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading and testing saved models\n",
    "2. Creating prediction functions for deployment\n",
    "3. API design (Flask example)\n",
    "4. Docker containerization\n",
    "5. CI/CD pipeline setup\n",
    "6. Monitoring and maintenance strategies\n",
    "\n",
    "## What You Need for Deployment:\n",
    "\n",
    "‚úÖ **Already have** (from previous notebooks):\n",
    "- Trained models (best_model.pkl, pycaret_model.pkl)\n",
    "- Streamlit app (app.py)\n",
    "- Preprocessing pipeline\n",
    "\n",
    "üîú **This notebook provides**:\n",
    "- API code for backend\n",
    "- Docker configuration\n",
    "- CI/CD automation\n",
    "- Monitoring tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL DEPLOYMENT GUIDE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL DEPLOYMENT GUIDE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "  best_model.pkl (0.49 MB)\n",
      "  pycaret_model.pkl (1.35 MB)\n",
      "\n",
      "‚úì Loaded: LightGBM\n",
      "  Test R¬≤: 0.6836\n",
      "  Test MAE: ¬£61,409\n"
     ]
    }
   ],
   "source": [
    "# Check available models\n",
    "model_dir = Path(\"../data/clean/\")\n",
    "models = list(model_dir.glob(\"*.pkl\"))\n",
    "\n",
    "print(\"Available models:\")\n",
    "for m in models:\n",
    "    size_mb = m.stat().st_size / (1024*1024)\n",
    "    print(f\"  {m.name} ({size_mb:.2f} MB)\")\n",
    "\n",
    "# Load best model\n",
    "try:\n",
    "    model_bundle = joblib.load(model_dir / \"best_model.pkl\")\n",
    "    \n",
    "    # Check if it's a proper bundle or just the model\n",
    "    if isinstance(model_bundle, dict) and 'model' in model_bundle:\n",
    "        print(f\"\\n‚úì Loaded: {model_bundle.get('model_name', 'Unknown')}\")\n",
    "        print(f\"  Test R¬≤: {model_bundle['metrics']['test_r2']:.4f}\")\n",
    "        print(f\"  Test MAE: ¬£{model_bundle['metrics']['test_mae']:,.0f}\")\n",
    "    else:\n",
    "        # It's just a model, not a bundle - create a minimal bundle\n",
    "        print(\"\\n‚ö† Model file doesn't have metadata, creating minimal bundle...\")\n",
    "        model_bundle = {\n",
    "            'model': model_bundle,\n",
    "            'model_name': 'LightGBM',\n",
    "            'metrics': {'test_r2': 0.0, 'test_mae': 50000},\n",
    "            'feature_names': None,\n",
    "            'target_encoder': None\n",
    "        }\n",
    "        print(\"  Note: Run notebook 4 to create a proper model bundle with metrics\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error loading model: {e}\")\n",
    "    print(\"   Please run notebook 4 first to create best_model.pkl\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Production-Ready Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Prediction function ready (FIXED: always applies expm1)\n"
     ]
    }
   ],
   "source": [
    "def predict_price(property_type, is_new, duration, county, year, month=1, quarter=1):\n",
    "    \"\"\"\n",
    "    Production prediction function with validation.\n",
    "    \n",
    "    Returns: dict with price and confidence interval\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    assert property_type in ['D','S','T','F','O'], \"Invalid property_type\"\n",
    "    assert is_new in ['Y','N'], \"Invalid is_new\"\n",
    "    assert duration in ['F','L','U'], \"Invalid duration\"\n",
    "    assert 1995 <= year <= 2025, \"Year out of range\"\n",
    "    \n",
    "    # Create input\n",
    "    input_data = pd.DataFrame([{\n",
    "        'type': property_type,\n",
    "        'is_new': is_new,\n",
    "        'duration': duration,\n",
    "        'county': county.upper(),\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'quarter': quarter\n",
    "    }])\n",
    "    \n",
    "    # Get model components\n",
    "    model = model_bundle['model']\n",
    "    encoder = model_bundle.get('target_encoder')\n",
    "    features = model_bundle.get('feature_names')\n",
    "    \n",
    "    # Preprocess based on available components\n",
    "    if encoder is not None and 'county' in input_data.columns:\n",
    "        try:\n",
    "            input_data['county_encoded'] = encoder.transform(input_data[['county']])\n",
    "            input_data = input_data.drop('county', axis=1)\n",
    "        except:\n",
    "            # If encoding fails, use default encoding\n",
    "            input_data['county_encoded'] = 0.0\n",
    "            input_data = input_data.drop('county', axis=1)\n",
    "    elif 'county' in input_data.columns:\n",
    "        input_data = input_data.drop('county', axis=1)\n",
    "    \n",
    "    # One-hot encode categorical variables\n",
    "    input_data = pd.get_dummies(input_data, columns=['type','is_new','duration'], drop_first=True)\n",
    "    \n",
    "    # Align features if we have the feature list\n",
    "    if features is not None:\n",
    "        for col in features:\n",
    "            if col not in input_data.columns:\n",
    "                input_data[col] = 0\n",
    "        input_data = input_data[features]\n",
    "    \n",
    "    # Predict (model was trained with log-transformed target)\n",
    "    prediction_log = model.predict(input_data)[0]\n",
    "    \n",
    "    # ALWAYS apply inverse transform (expm1 is inverse of log1p)\n",
    "    # The model was trained on np.log1p(price), so predictions are in log space\n",
    "    price = np.expm1(prediction_log)\n",
    "    \n",
    "    # Get MAE for confidence interval\n",
    "    mae = model_bundle.get('metrics', {}).get('test_mae', 50000)\n",
    "    \n",
    "    return {\n",
    "        'price': float(price),\n",
    "        'price_log': float(prediction_log),\n",
    "        'confidence_lower': float(max(1000, price - 2*mae)),\n",
    "        'confidence_upper': float(price + 2*mae),\n",
    "        'model': model_bundle.get('model_name', 'Unknown')\n",
    "    }\n",
    "\n",
    "print(\"‚úì Prediction function ready (FIXED: always applies expm1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST PREDICTIONS (FIXED)\n",
      "================================================================================\n",
      "\n",
      "London Flat (New Build, Leasehold):\n",
      "  Predicted Price: ¬£754,848\n",
      "  Log Value: 13.5343\n",
      "  Confidence Range: ¬£632,030 - ¬£877,666\n",
      "  Model: LightGBM\n",
      "\n",
      "Manchester Semi-Detached (Freehold):\n",
      "  Predicted Price: ¬£248,214\n",
      "  Log Value: 12.4221\n",
      "  Confidence Range: ¬£125,396 - ¬£371,031\n",
      "  Model: LightGBM\n",
      "\n",
      "Cornwall Detached (Freehold):\n",
      "  Predicted Price: ¬£321,911\n",
      "  Log Value: 12.6820\n",
      "  Confidence Range: ¬£199,093 - ¬£444,728\n",
      "  Model: LightGBM\n",
      "\n",
      "================================================================================\n",
      "‚úÖ All predictions now show realistic UK house prices!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test cases\n",
    "tests = [\n",
    "    (\"London Flat (New Build, Leasehold)\", 'F', 'Y', 'L', 'GREATER LONDON', 2016),\n",
    "    (\"Manchester Semi-Detached (Freehold)\", 'S', 'N', 'F', 'GREATER MANCHESTER', 2015),\n",
    "    (\"Cornwall Detached (Freehold)\", 'D', 'N', 'F', 'CORNWALL', 2017)\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEST PREDICTIONS (FIXED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, *params in tests:\n",
    "    result = predict_price(*params)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Predicted Price: ¬£{result['price']:,.0f}\")\n",
    "    print(f\"  Log Value: {result['price_log']:.4f}\")\n",
    "    print(f\"  Confidence Range: ¬£{result['confidence_lower']:,.0f} - ¬£{result['confidence_upper']:,.0f}\")\n",
    "    print(f\"  Model: {result['model']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ All predictions now show realistic UK house prices!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Flask API Code\n",
    "\n",
    "Save this as `api.py` for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì API code saved: api_example.py\n"
     ]
    }
   ],
   "source": [
    "api_code = '''from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "model_bundle = joblib.load('data/clean/best_model.pkl')\n",
    "\n",
    "@app.route('/health')\n",
    "def health():\n",
    "    return jsonify({'status': 'ok', 'model': model_bundle['model_name']})\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    result = predict_price(**data)  # Use function from above\n",
    "    return jsonify(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "'''\n",
    "\n",
    "with open('api_example.py', 'w') as f:\n",
    "    f.write(api_code)\n",
    "\n",
    "print(\"‚úì API code saved: api_example.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Docker Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Docker files created\n",
      "Run: docker-compose up --build\n"
     ]
    }
   ],
   "source": [
    "# Dockerfile\n",
    "dockerfile = '''FROM python:3.9-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "EXPOSE 5000\n",
    "CMD [\"python\", \"api.py\"]\n",
    "'''\n",
    "\n",
    "# docker-compose.yml\n",
    "compose = '''version: '3.8'\n",
    "services:\n",
    "  api:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"5000:5000\"\n",
    "    volumes:\n",
    "      - ./data:/app/data\n",
    "'''\n",
    "\n",
    "with open('Dockerfile.example', 'w') as f:\n",
    "    f.write(dockerfile)\n",
    "with open('docker-compose.example.yml', 'w') as f:\n",
    "    f.write(compose)\n",
    "\n",
    "print(\"‚úì Docker files created\")\n",
    "print(\"Run: docker-compose up --build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GitHub Actions CI/CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì CI/CD workflow created\n"
     ]
    }
   ],
   "source": [
    "workflow = '''name: Deploy\n",
    "on:\n",
    "  push:\n",
    "    branches: [ main ]\n",
    "jobs:\n",
    "  deploy:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "    - uses: actions/checkout@v2\n",
    "    - name: Build\n",
    "      run: docker build -t housing-model .\n",
    "    - name: Deploy\n",
    "      run: echo \"Deploy to production\"\n",
    "'''\n",
    "\n",
    "import os\n",
    "os.makedirs('.github/workflows', exist_ok=True)\n",
    "with open('.github/workflows/deploy.example.yml', 'w') as f:\n",
    "    f.write(workflow)\n",
    "\n",
    "print(\"‚úì CI/CD workflow created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deployment Checklist\n",
    "\n",
    "### Before Deployment:\n",
    "- [x] Model trained (R¬≤ > 0.65)\n",
    "- [x] Model saved with preprocessing\n",
    "- [x] Prediction function tested\n",
    "- [x] Streamlit app working (`app.py`)\n",
    "- [ ] API created and tested\n",
    "- [ ] Docker container built\n",
    "- [ ] Error handling added\n",
    "- [ ] Monitoring set up\n",
    "\n",
    "### Deployment Options:\n",
    "\n",
    "**1. Heroku (Easiest)**\n",
    "```bash\n",
    "heroku create\n",
    "git push heroku main\n",
    "```\n",
    "\n",
    "**2. Oracle Cloud (Free)**\n",
    "- Always Free compute\n",
    "- Good for students\n",
    "\n",
    "**3. Local/Pi**\n",
    "- Use ngrok for demos\n",
    "\n",
    "### After Deployment:\n",
    "- Monitor latency (< 100ms)\n",
    "- Log predictions\n",
    "- Retrain monthly\n",
    "- Collect feedback\n",
    "\n",
    "---\n",
    "\n",
    "**Your Streamlit app (`app.py`) is already deployment-ready!**\n",
    "\n",
    "**End of Deployment Guide**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
